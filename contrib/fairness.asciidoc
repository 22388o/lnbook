=== Trust, Fairness and Enforcement

Cryptographic systems like Bitcoin and the Lightning Network are systems that allow you to transact with people (and computers) that you don't trust. This is often referred to as "trustless" operation, even though it is not actually trustless. You have to trust in the software that you run and you have to trust that the protocol implemented by that software will result in fair outcomes.

The big distinction between a cryptographic system like this and a traditional financial system, is that in traditional finance you trust a _trusted third party_, for example a bank, to ensure that outcomes are fair. The problem that we identify with such systems is that they give too much power to the third party and they are also vulnerable to a _single point of failure_. If the trusted third party itself violates your trust or attempts to cheat, the basis of trust breaks.

As you study cryptographic systems, you will notice a certain pattern: these systems attempt to prevent unfair outcomes by using a system of incentives and disincentives, instead of relying on a trusted third party. In cryptographic systems you place trust in the _protocol_, which is a process that ensures the incentives and disincentives are applied correctly. The advantage of this approach is two fold. Not only do you avoid trusting a third party, you also reduce the need to enforce fair outcomes. The system only needs to keep the participants following the agreed protocol. As long as participants stick to the protocol, the incentive mechanism in that protocol achieves fair outcomes without enforcement.

The use of incentives and disincentives to achieve fair outcomes is one aspect of a branch of mathematics called _game theory_, which studies "models of stategic interaction among rational decision makers" footnote:[Wikipedia "Game Theory": https://en.wikipedia.org/wiki/Game_theory]. Cryptographic systems that control financial interactions between participants, such as Bitcoin and the Lightning Network rely heavily on game theory to prevent participants from cheating and allow participants who don't trust each other to achieve fair outcomes.

While game theory and it's use in cryptographic systems will appear confounding and unfamiliar at first, we can use simple examples from our childhood to understand the basic patterns. Once you understand these basic patterns you will see them everywhere in the blockchain space and you will come to recognize them quickly and intuitively.

In this book, we call this pattern a _Fairness Protocol_ defined as a process that uses a system of incentives and/or disincentives to ensure fair outcomes for participants who don't trust each other. Enforcement of a fairness protocol is only necessary to ensure that the participants can't escape the incentives or disincentives.

==== A fairness protocol in action

Let's look at an example of a fairness protocol, which may be familiar to any reader, perhaps as a memory from their childhood.

Our story starts with a family lunch. A parent has prepared a bowl of fried potatoes ("french fries" or "chips" depending on which English dialect you use). Two siblings must share the plate of chips. The parent must ensure a fair outcome, in order to prevent an outbreak of violence. This story is all too familiar to many families but is actually drawn directly from the experience of one of the authors who had to watch these daily fights over chips.

There are several ways that fairness can be achieved in this scenario. The naive but commonly used method is for the parent to use their authority as a trusted third party: they split the bowl of chips into two servings. This is similar to a traditional banking scenario, where the bank acts as a trusted third party to prevent any cheating between two customers who transact.

The problem with this scenario is that this puts a lot of power in the hands of the trusted third party. The parent is accused of playing favorites and not sharing the chips equally. The siblings may fight over the chips, dragging the parent into their fight.

But a much better solution exists: the siblings are taught to play a game called "split and choose". At each lunch they take turns, such that one sibling splits the bowl of chips into two servings and the *other* sibling gets to choose which serving they want. Almost immediately, the siblings figure out the dynamic of this game. If the one splitting makes a mistake or tries to cheat, the other sibling can "punish" them by choosing the bigger bowl. It is in the best interest of both siblings, but especially the one splitting the bowl, to play fair. Only the cheater loses in this scenario. The parent doesn't even have to use their authority or enforce fairness. All the parent has to do is _enforce the protocol_. As long as the siblings cannot escape their assigned roles of "splitter" and "chooser", the protocol itself ensures a fair outcome without the need for any intervention. The parent can't play favorites or distort the outcome.
